{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacob/opt/anaconda3/lib/python3.8/_collections_abc.py:832: MatplotlibDeprecationWarning: Support for setting the 'text.latex.preamble' or 'pgf.preamble' rcParam to a list of strings is deprecated since 3.3 and will be removed two minor releases later; set it to a single string instead.\n",
      "  self[key] = other[key]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "params = {'text.latex.preamble' : [r'\\usepackage{siunitx}', r'\\usepackage{amsmath}']}\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = pd.read_csv('dataset_without_rep.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_profs = pd.read_excel('20211012_MissingProfiles.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "investor_uuid = []\n",
    "profile_id = []\n",
    "fail = '#FAIL!'\n",
    "missing_prof = 'Profile not found or no longer available'\n",
    "\n",
    "for x in range(0,len(missing_profs)):\n",
    "    investor_uuid.append(missing_profs.iloc[x,0])\n",
    "    if type(missing_profs['misc'][x]) == float:\n",
    "        profile_id.append(np.nan)\n",
    "    elif missing_profs['misc'][x] == fail:\n",
    "        profile_id.append(np.nan)\n",
    "    elif missing_profs['misc'][x].split(\":\")[1].split(\",\")[0].replace('\"', '') == missing_prof:\n",
    "        profile_id.append(np.nan)\n",
    "    else:\n",
    "        profile_id.append(missing_profs['misc'][x].split(\":\")[1].split(\",\")[0].replace('\"', ''))\n",
    "df1 = pd.DataFrame({'investor_uuid': investor_uuid})\n",
    "df2 = pd.DataFrame({'profile_id': profile_id})\n",
    "        \n",
    "missing_linkedin_mapping = pd.concat([df2,df1], axis=1)\n",
    "missing_linkedin_mapping.dropna(inplace=True)\n",
    "missing_linkedin_mapping.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_df_without = model_df.drop(columns = to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_work_vectors = pd.read_csv('missing_profiles_job_title_vectors.csv')\n",
    "missing_education_vectors = pd.read_csv('missing_profiles_education_vectors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import HC tables\n",
    "age_proxy = pd.read_csv(\"age_proxy.csv\")\n",
    "\n",
    "work_vectors = pd.read_csv(\"work_vectors.csv\")\n",
    "work_vectors = work_vectors.append(missing_work_vectors)\n",
    "work_vectors.reset_index(inplace=True, drop=True)\n",
    "\n",
    "education_vectors = pd.read_csv(\"education_vectors.csv\")\n",
    "education_vectors = education_vectors.append(missing_education_vectors)\n",
    "education_vectors.reset_index(inplace=True, drop=True)\n",
    "\n",
    "cleaned_board_positions = pd.read_csv(\"cleaned_board_positions.csv\")\n",
    "cleaned_work_data = pd.read_csv(\"cleaned_work_data.csv\")\n",
    "cleaned_education_data = pd.read_csv(\"cleaned_education_data.csv\")\n",
    "\n",
    "linkedin=pd.read_csv('linkedin_crunchbase_mapping_1.csv')\n",
    "linkedin = linkedin.append(missing_linkedin_mapping)\n",
    "linkedin.reset_index(inplace=True, drop=True)\n",
    "\n",
    "top_unis = pd.read_excel('top_unis.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#match investor uuid to linkedin uuid to use HC tables\n",
    "model_df['linkedin_id'] = model_df.investor_uuid.map(linkedin.set_index('investor_uuid')['profile_id'].to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: excluded due to too many missing values\n",
    "\n",
    "#given the estimated bachelor and master ages of the investor, take the average of the two if the investor has a master's and a bachelor's, else take what is available\n",
    "# age_proxy[\"avg_age\"] = age_proxy.index\n",
    "# for x in range(0,len(age_proxy)):\n",
    "#     if pd.isna(age_proxy.bachelor_age_proxy[x])==True:\n",
    "#         age_proxy[\"avg_age\"][x]=age_proxy[\"master_age_proxy\"][x]\n",
    "#     elif pd.isna(age_proxy.master_age_proxy[x])==True:\n",
    "#         age_proxy[\"avg_age\"][x]=age_proxy[\"bachelor_age_proxy\"][x]\n",
    "#     else:\n",
    "#         age_proxy[\"avg_age\"][x]=(age_proxy[\"bachelor_age_proxy\"][x]+age_proxy[\"master_age_proxy\"][x]) / 2\n",
    "        \n",
    "# model_df['avg_age_investor'] = model_df.linkedin_id.map(age_proxy.set_index('profile_id')['avg_age'].to_dict())\n",
    "\n",
    "# print(model_df['avg_age_investor'].isna().sum(), 'investors without match')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "work_legal missing for 288 investors\n",
      "work_finance missing for 288 investors\n",
      "work_consulting_strategy missing for 288 investors\n",
      "work_entrepreneurship missing for 288 investors\n",
      "work_sales_hr_pr_marketing missing for 288 investors\n",
      "work_healthcare_life_science missing for 288 investors\n",
      "work_science_research_academic missing for 288 investors\n",
      "work_technology_engineering missing for 288 investors\n",
      "work_c_suite missing for 288 investors\n",
      "work_board_mentor_advisor missing for 288 investors\n",
      "work_design_journalism_writing missing for 288 investors\n",
      "work_investing missing for 288 investors\n"
     ]
    }
   ],
   "source": [
    "#add the work vectors columns to the investors\n",
    "columns = work_vectors.drop(columns=['Unnamed: 0', 'profile_id'])\n",
    "for col in columns:\n",
    "    model_df[col] = model_df.linkedin_id.map(work_vectors.set_index('profile_id')[col].to_dict())\n",
    "    print(col, 'missing for', model_df[col].isna().sum(), \"investors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edu_legal missing for 482 investors\n",
      "edu_banking_finance_macro missing for 482 investors\n",
      "edu_business missing for 482 investors\n",
      "edu_social_science missing for 482 investors\n",
      "edu_human_science missing for 482 investors\n",
      "edu_life_science_healthcare missing for 482 investors\n",
      "edu_natural_science missing for 482 investors\n",
      "edu_math_physics missing for 482 investors\n",
      "edu_computer_science missing for 482 investors\n",
      "edu_engineering missing for 482 investors\n"
     ]
    }
   ],
   "source": [
    "#add the educational vectors columns to the investors\n",
    "columns = education_vectors.drop(columns=['Unnamed: 0', 'profile_id'])\n",
    "for col in columns:\n",
    "    model_df[col] = model_df.linkedin_id.map(education_vectors.set_index('profile_id')[col].to_dict())\n",
    "    print(col, 'missing for', model_df[col].isna().sum(), \"investors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exported on 18 Jan 2022\n",
    "\n",
    "model_df.dropna(inplace=True)\n",
    "model_df.drop(columns='linkedin_id', inplace=True)\n",
    "model_df.to_csv('model_df_HC_final.csv', index=False)\n",
    "\n",
    "# model_hc = model_df\n",
    "# model_df = pd.read_csv('dataset_without_rep.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hc = pd.read_csv('model_df_HC_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "827"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_hc.investor_uuid.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: excluded due to too many missing values \n",
    "\n",
    "#determine the number of board positions for each profile id\n",
    "# num_board_positions = cleaned_board_positions.groupby('profile_id').count()\n",
    "# num_board_positions.reset_index(inplace=True)\n",
    "# num_board_positions = num_board_positions[['profile_id', 'RAW_company_name']]\n",
    "# num_board_positions.rename(columns={'RAW_company_name':'number_board_positions'}, inplace=True)\n",
    "\n",
    "#add the number of board positions per investor\n",
    "# model_df['number_board_positions'] = model_df.linkedin_id.map(num_board_positions.set_index('profile_id')['number_board_positions'].to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: excluded due to too many missing values \n",
    "\n",
    "# #determine the duration of each position \n",
    "# cleaned_work_data['duration'] = cleaned_work_data['ended_on_year'] - cleaned_work_data['started_on_year']\n",
    "# cleaned_work_data.loc[cleaned_work_data['ended_on_month'] > cleaned_work_data['started_on_month'], 'duration'] = cleaned_work_data.loc[cleaned_work_data['ended_on_month'] > cleaned_work_data['started_on_month'], 'duration'] + ((cleaned_work_data.loc[cleaned_work_data['ended_on_month'] > cleaned_work_data['started_on_month'], 'ended_on_month'] - cleaned_work_data.loc[cleaned_work_data['ended_on_month'] > cleaned_work_data['started_on_month'], 'started_on_month'])/12)\n",
    "# cleaned_work_data.loc[cleaned_work_data['ended_on_month'] < cleaned_work_data['started_on_month'], 'duration'] = cleaned_work_data.loc[cleaned_work_data['ended_on_month'] < cleaned_work_data['started_on_month'], 'duration'] - ((cleaned_work_data.loc[cleaned_work_data['ended_on_month'] < cleaned_work_data['started_on_month'], 'started_on_month'] - cleaned_work_data.loc[cleaned_work_data['ended_on_month'] < cleaned_work_data['started_on_month'], 'ended_on_month'])/12)\n",
    "\n",
    "# #create a table that aggregates all the years of experience and number of jobs as well as a relation between the two\n",
    "# years_exp = cleaned_work_data.groupby('profile_id').agg({\n",
    "#     'duration': 'sum'\n",
    "#     , 'RAW_company_name': 'count'\n",
    "# })\n",
    "# years_exp.reset_index(inplace=True)\n",
    "# years_exp['overall']=years_exp['duration']/years_exp['RAW_company_name']\n",
    "\n",
    "# #TODO: experiment with using each or all of these work columns\n",
    "# model_df['years_work_exp'] = model_df.linkedin_id.map(years_exp.set_index('profile_id')['duration'].to_dict())\n",
    "# model_df['num_jobs'] = model_df.linkedin_id.map(years_exp.set_index('profile_id')['RAW_company_name'].to_dict())\n",
    "# model_df['total_work_exp'] = model_df.linkedin_id.map(years_exp.set_index('profile_id')['overall'].to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: excluded due to too many missing values \n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\", 'This pattern has match groups')\n",
    "\n",
    "# #create long string of all top unis concat together\n",
    "# top_unis_list = top_unis.name\n",
    "# top_unis_values = '|'.join(str(v) for v in top_unis_list)\n",
    "\n",
    "# #if the school name is in the top_uni_values object, set top_uni = 1\n",
    "# cleaned_education_data['top_uni'] = cleaned_education_data.school_name.str.contains(top_unis_values)\n",
    "# cleaned_education_data['top_uni'].replace([True, False], [1,0], inplace=True)\n",
    "\n",
    "# #turn degree label into dummy\n",
    "# degree_dummy = pd.get_dummies(cleaned_education_data['degree_label'])\n",
    "# cleaned_education_data = pd.concat([cleaned_education_data, degree_dummy], axis = 1)\n",
    "\n",
    "# #get the maximum value for each individual investor, showing if they ever went to a top uni or received a bachelor, master, or doctorate degree\n",
    "# cleaned_education_data_investor = cleaned_education_data.groupby('profile_id').agg({\n",
    "#     'top_uni': 'max'\n",
    "#     , 'Bachelor': 'max'\n",
    "#     , 'Master': 'max'\n",
    "#     , 'Doctor': 'max'\n",
    "# })\n",
    "\n",
    "# #clean intermediate df\n",
    "# cleaned_education_data_investor.reset_index(inplace=True)\n",
    "# cleaned_education_data_investor.rename(columns = {'Bachelor':'has_bachelor', 'Master':'has_master', 'Doctor':'has_doctor'}, inplace = True)\n",
    "\n",
    "# #add education variables per investor\n",
    "# columns = cleaned_education_data_investor.drop(columns='profile_id').columns\n",
    "# for col in columns:\n",
    "#     model_df[col] = model_df.linkedin_id.map(cleaned_education_data_investor.set_index('profile_id')[col].to_dict())\n",
    "    \n",
    "# # model_df.to_csv('model_df_HC_25_Nov.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
